{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acedab3e-8a66-494a-8906-869be19e5bac",
   "metadata": {},
   "source": [
    "Q1. What is the KNN algorithm?\n",
    "\n",
    "The KNN (K-Nearest Neighbors) algorithm classifies data based on the closest training examples in the feature space, using majority voting among the nearest neighbors.\n",
    "\n",
    "Q2. How do you choose the value of K in KNN?\n",
    "\n",
    "Choosing the value of K involves using cross-validation, starting with small K, increasing incrementally, and selecting the K that minimizes error rates.\n",
    "\n",
    "Q3. What is the difference between KNN classifier and KNN regressor?\n",
    "\n",
    "KNN classifier predicts categorical labels by majority voting among neighbors, while KNN regressor predicts continuous values by averaging the neighbors' values.\n",
    "\n",
    "Q4. How do you measure the performance of KNN?\n",
    "\n",
    "Performance is measured using metrics like accuracy, precision, recall, F1-score for classification, and mean squared error, R-squared for regression.\n",
    "\n",
    "Q5. What is the curse of dimensionality in KNN?\n",
    "\n",
    "The curse of dimensionality refers to the exponential increase in data sparsity and computational complexity as the number of dimensions increases, degrading KNN performance.\n",
    "\n",
    "Q6. How do you handle missing values in KNN?\n",
    "\n",
    "Handle missing values by imputing them using mean, median, or mode of the nearest neighbors' values, or by using advanced imputation techniques.\n",
    "\n",
    "Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?\n",
    "\n",
    "KNN classifier is best for classification problems, predicting discrete labels. KNN regressor suits regression problems, predicting continuous values. Performance depends on the dataset.\n",
    "\n",
    "Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?\n",
    "\n",
    "Strengths: simplicity, non-parametric, effective with enough data. Weaknesses: computationally expensive, sensitive to irrelevant features. Address by feature selection, scaling, and efficient computation techniques.\n",
    "\n",
    "Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?\n",
    "\n",
    "Euclidean distance measures straight-line distance between points, while Manhattan distance sums the absolute differences along each dimension. Choice affects neighbor determination.\n",
    "\n",
    "Q10. What is the role of feature scaling in KNN?**\n",
    "\n",
    "Feature scaling ensures all features contribute equally to distance calculations, preventing dominance by features with larger scales, thus improving KNN performance and accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
